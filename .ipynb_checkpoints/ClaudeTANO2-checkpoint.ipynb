{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "import platform\n",
    "\n",
    "def get_gpu_info():\n",
    "    print(\"PyTorch GPU Information:\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA is available. PyTorch version: {torch.__version__}\")\n",
    "        print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"\\nGPU {i}:\")\n",
    "            print(f\"  Name: {torch.cuda.get_device_name(i)}\")\n",
    "            print(f\"  Compute capability: {torch.cuda.get_device_capability(i)}\")\n",
    "            print(f\"  Total memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n",
    "            \n",
    "        # Current device information\n",
    "        current_device = torch.cuda.current_device()\n",
    "        print(f\"\\nCurrent GPU: {current_device}\")\n",
    "        print(f\"  Name: {torch.cuda.get_device_name(current_device)}\")\n",
    "        \n",
    "        # Memory information\n",
    "        print(\"\\nMemory Usage:\")\n",
    "        print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"  Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. Running on CPU.\")\n",
    "\n",
    "    # System GPU information (platform-dependent)\n",
    "    if platform.system() == \"Windows\":\n",
    "        try:\n",
    "            gpu_info = subprocess.check_output([\"nvidia-smi\"]).decode('utf-8')\n",
    "            print(\"\\nNVIDIA-SMI Output:\")\n",
    "            print(gpu_info)\n",
    "        except:\n",
    "            print(\"\\nNVIDIA-SMI is not available on this system.\")\n",
    "    elif platform.system() == \"Linux\":\n",
    "        try:\n",
    "            gpu_info = subprocess.check_output([\"nvidia-smi\"]).decode('utf-8')\n",
    "            print(\"\\nNVIDIA-SMI Output:\")\n",
    "            print(gpu_info)\n",
    "        except:\n",
    "            print(\"\\nNVIDIA-SMI is not available on this system.\")\n",
    "    elif platform.system() == \"Darwin\":  # macOS\n",
    "        print(\"\\nOn macOS, detailed GPU information might not be available through nvidia-smi.\")\n",
    "        print(\"For Apple Silicon (M1/M2) Macs, GPU information is limited.\")\n",
    "    else:\n",
    "        print(\"\\nUnable to retrieve system GPU information for this platform.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define Generator and Discriminator for time series\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=3, batch_first=True)\n",
    "        #self.linearh = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear1 = nn.Linear(hidden_dim, 1)\n",
    "        #self.relu = nn.ReLU()\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.linearh(x)\n",
    "        #x = self.relu(x)\n",
    "        return self.linear1(x)\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'bias' in name:\n",
    "                        nn.init.constant_(param, 0.0)\n",
    "                    elif 'weight' in name:\n",
    "                        nn.init.xavier_normal_(param)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=3, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x[:, -1, :])  # Only use the last output\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'bias' in name:\n",
    "                        nn.init.constant_(param, 0.0)\n",
    "                    elif 'weight' in name:\n",
    "                        nn.init.xavier_normal_(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngsim_dataset import NGSIMDataset\n",
    "# settings for data loader\n",
    "class DataSettings:\n",
    "    def __init__(self):\n",
    "        # location of datasets and category\n",
    "        end_name = 'ngsim_sample.csv' # dataset name\n",
    "        data_file = end_name # dataset category and dataset name\n",
    "        # key = 'realKnownCause/'+end_name # This key is used for reading anomaly labels\n",
    "        \n",
    "        self.BASE = '/workspace/ClaudeTANOGAN/NGSIM_Dataset'\n",
    "        # check if self.BASE has the last '/'\n",
    "        if self.BASE[-1] != '/':\n",
    "            self.BASE += '/'\n",
    "        # self.label_file = 'labels\\\\combined_windows.json'\n",
    "        self.data_file = data_file\n",
    "        # self.key = key\n",
    "        self.train = True\n",
    "        self.window_length = 60\n",
    "        self.column_name = 'Velocity'\n",
    "\n",
    "dataset = NGSIMDataset(data_settings = DataSettings())\n",
    "print(f'Shape of dataset: {dataset.x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_series(ngsim_dataset, n=5):\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    for i in range(n):\n",
    "        plt.plot(ngsim_dataset.x[i])\n",
    "    plt.title('Training Sequences')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Velocity')\n",
    "    plt.show()\n",
    "\n",
    "plot_series(dataset, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "seq_len = 60\n",
    "input_dim = 1\n",
    "hidden_dim = 128\n",
    "batch_size = 32\n",
    "num_epochs = 10_000\n",
    "\n",
    "def model_initialization():\n",
    "    # Initialize models and optimizers\n",
    "    generator = Generator(input_dim, hidden_dim, seq_len)\n",
    "    discriminator = Discriminator(input_dim, hidden_dim, seq_len)\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "    # Summary of the models\n",
    "    print(\"=====Generator=====\")\n",
    "    print(generator)\n",
    "    print(\"=====Discriminator=====\")\n",
    "    print(discriminator)\n",
    "    # print(\"=====Generator Optimizer=====\")\n",
    "    # print(g_optimizer)\n",
    "    # print(\"=====Discriminator Optimizer=====\")\n",
    "    # print(d_optimizer)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    print('Model initialization OK')\n",
    "    return generator, discriminator, g_optimizer, d_optimizer, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models and optimizers\n",
    "generator, discriminator, g_optimizer, d_optimizer, criterion = model_initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all files in qualitycheck folder\n",
    "import os\n",
    "import shutil\n",
    "folder = 'qualitycheck'\n",
    "\n",
    "# If folder does not exist, create it\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pretraining the generator** ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the generator to the GPU\n",
    "generator = generator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_losses = []\n",
    "num_epochs = 10_000\n",
    "batch_size = 32\n",
    "pretrain_crit = nn.MSELoss()\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0003)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Generate real data\n",
    "    # real_data = torch.tensor(np.repeat(dataset.x[0].reshape(1, 60, 1), batch_size, axis=0), dtype=torch.float32).to(device)\n",
    "    real_data = torch.tensor(dataset.x[np.random.choice(len(dataset), batch_size)], dtype=torch.float32).to(device)\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    # Fake data\n",
    "    z = torch.randn(batch_size, seq_len, input_dim, device=device)\n",
    "    fake_data = generator(z)\n",
    "    \n",
    "    # Update the generator\n",
    "    g_loss = pretrain_crit(fake_data, real_data)\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], g_loss: {g_loss.item():.4f}')\n",
    "        g_losses.append(g_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assume generator and device are already defined\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# generator = generator.to(device)\n",
    "\n",
    "# Generate some examples from the generator\n",
    "z = torch.randn(5, seq_len, input_dim, device=device)\n",
    "with torch.no_grad():\n",
    "    fake_data = generator(z).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "for i in range(5):\n",
    "    plt.plot(fake_data[i])\n",
    "plt.title('Generated Sequences')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(dataset.x[0])\n",
    "plt.title('Original Sequence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models and optimizers\n",
    "generator, discriminator, g_optimizer, d_optimizer, criterion = model_initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all files in qualitycheck folder\n",
    "import os\n",
    "import shutil\n",
    "folder = 'qualitycheck'\n",
    "\n",
    "# If folder does not exist, create it\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move the generator to the GPU\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "num_epochs = 10_000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Generate real data\n",
    "    real_data = torch.tensor(dataset.x[np.random.choice(len(dataset), batch_size)], dtype=torch.float32).to(device)\n",
    "\n",
    "    # Train Discriminator\n",
    "    d_optimizer.zero_grad()\n",
    "    \n",
    "    # Real data\n",
    "    real_labels = torch.ones(batch_size, 1).to(device)\n",
    "    outputs = discriminator(real_data)\n",
    "    d_loss_real = criterion(outputs, real_labels)\n",
    "    \n",
    "    # Fake data\n",
    "    z = torch.randn(batch_size, seq_len, input_dim).to(device)\n",
    "    fake_data = generator(z)\n",
    "    fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "    outputs = discriminator(fake_data.detach())\n",
    "    d_loss_fake = criterion(outputs, fake_labels)\n",
    "    \n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    if epoch == 0:\n",
    "        print(f'** -> ** Initial losses: d_loss: {d_loss.item():.4f}')\n",
    "    d_loss.backward()\n",
    "    # d_optimizer.step()\n",
    "\n",
    "    # Train Generator\n",
    "    g_optimizer.zero_grad()\n",
    "    z = torch.randn(batch_size, seq_len, input_dim).to(device)\n",
    "    fake_data = generator(z)\n",
    "    outputs = discriminator(fake_data)\n",
    "    g_loss = criterion(outputs, real_labels)\n",
    "    if epoch == 0:\n",
    "        print(f'** -> ** g_loss: {g_loss.item():.4f}')\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n",
    "        d_losses.append(d_loss.item())\n",
    "        g_losses.append(g_loss.item())\n",
    "        # Sample the generator to check the quality of the generated samples\n",
    "        z = torch.randn(1, seq_len, input_dim).to(device)\n",
    "        fake_data = generator(z).detach().cpu().numpy().reshape(seq_len)\n",
    "        plt.figure(figsize=(4, 2))\n",
    "        plt.plot(fake_data)\n",
    "        plt.title('Generated Sequence')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Velocity')\n",
    "        plt.savefig(f'qualitycheck/seq_{epoch+1}.png')\n",
    "\n",
    "    #if (epoch + 1) % 2000 == 0:\n",
    "        \n",
    "    #    user_input = input(\"Do you want to continue training? (yes/no): \")\n",
    "    #    if user_input.lower() == \"no\":\n",
    "    #        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "plt.plot(d_losses, label='Discriminator Loss')\n",
    "plt.plot(g_losses, label='Generator Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.plot(dataset.x[np.random.choice(len(dataset), batch_size)][i,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    z = torch.randn(1, seq_len, input_dim)\n",
    "    fake_data = generator(z).detach().numpy().reshape(seq_len)\n",
    "    plt.plot(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
